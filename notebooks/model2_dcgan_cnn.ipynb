{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88485067",
   "metadata": {},
   "source": [
    "## Importing Needed Libraries\n",
    "\n",
    "<p align=\"justify\">insert spiel</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4359eb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: Preprocessing\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Part 2: Creating DCGAN Generator and Discriminator\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# Part 3: Training a DCGAN for Each Underrepresented Class (Cordana, Healthy, Pestalotiopsis)\n",
    "\n",
    "import shutil\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import os\n",
    "\n",
    "# https://docs.pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "# https://pyimagesearch.com/2021/10/25/training-a-dcgan-in-pytorch/\n",
    "# https://medium.com/@manoharmanok/implementing-dcgan-in-pytorch-using-the-celeba-dataset-a-comprehensive-guide-660e6e8e29d2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56d2cb2",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing\n",
    "\n",
    "<p align=\"justify\">insert spiel</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "411d5de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "RAW_DATA_DIR = \"../training_data\"\n",
    "GAN_SIZE = (128, 128)\n",
    "CNN_SIZE = (224, 224)\n",
    "BANANA_CLASSES  = [\"cordana\", \"healthy\", \"pestalotiopsis\", \"sigatoka\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a234d1bd",
   "metadata": {},
   "source": [
    "<p align=\"justify\">insert spiel</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8812e66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_gan = transforms.Compose([\n",
    "    transforms.Resize(GAN_SIZE),  # Resize for DCGAN\n",
    "    transforms.ToTensor(),        # Convert to tensor\n",
    "    transforms.Normalize(\n",
    "        [0.5, 0.5, 0.5], \n",
    "        [0.5, 0.5, 0.5],\n",
    "    )  # Normalize to [-1, 1] for DCGAN\n",
    "])\n",
    "\n",
    "transform_cnn = transforms.Compose([\n",
    "    transforms.Resize(CNN_SIZE),  # Resize for CNN\n",
    "    transforms.ToTensor(),        # Convert to tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ee0ae5",
   "metadata": {},
   "source": [
    "<p align=\"justify\">insert spiel</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53e02535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gan_data(batch_size = 32, workers = 2, target_class = None):\n",
    "    # Load full dataset with GAN transformations\n",
    "    dataset_gan = datasets.ImageFolder(root = RAW_DATA_DIR, transform = transform_gan)\n",
    "\n",
    "    if target_class:\n",
    "        # Get class index from the class name\n",
    "        class_index = dataset_gan.class_to_idx[target_class]\n",
    "\n",
    "        # Filter indices where target matches\n",
    "        indices = [i for i, (_, label) in enumerate(dataset_gan.samples) if label == class_index]\n",
    "\n",
    "        # Wrap in a Subset\n",
    "        dataset_gan = Subset(dataset_gan, indices)\n",
    "\n",
    "    # Create DataLoader for the GAN data\n",
    "    dataloader_gan = DataLoader(dataset_gan, batch_size = batch_size, shuffle = True, num_workers = workers)\n",
    "\n",
    "    return dataloader_gan\n",
    "\n",
    "def load_cnn_data(batch_size = 32, workers = 2):\n",
    "    # Load dataset with CNN transformations\n",
    "    dataset_cnn = datasets.ImageFolder(root=RAW_DATA_DIR, transform = transform_cnn)\n",
    "    \n",
    "    # Create DataLoader for the CNN data\n",
    "    dataloader_cnn = DataLoader(dataset_cnn, batch_size=batch_size, shuffle = True, num_workers = workers)\n",
    "\n",
    "    return dataloader_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d5c2ea",
   "metadata": {},
   "source": [
    "<p align=\"justify\">insert spiel</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "014a3b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    classname = model.__class__.__name__\n",
    "\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        nn.init.normal_(model.weight.data, 0.0, 0.02)\n",
    "\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        nn.init.normal_(model.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(model.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2af1f2",
   "metadata": {},
   "source": [
    "## Part 2: Creating the DCGAN Generator and Discriminator Classes\n",
    "\n",
    "<p align=\"justify\">insert spiel</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33db2f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "BATCH_SIZE = 128        # Number of images per training batch\n",
    "\n",
    "INPUT_DIMENSION = 100   # Dimensionality of the generator input\n",
    "\n",
    "NC = 3                  # Number of channels in the training images\n",
    "\n",
    "NGF = 64                # Base number of feature maps in the generator\n",
    "\n",
    "NDF = 64                # Base number of feature maps in Discriminator\n",
    "\n",
    "EPOCHS = 100            # Number of training epochs\n",
    "\n",
    "LEARNING_RATE = 0.0002  # Learning rate for both optimizers\n",
    "\n",
    "BETA1 = 0.5             # Beta1 value for the Adam optimizer to help stabilize DCGAN training\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
    "\n",
    "NGPU = 1  # Number of GPUs to use (0 means CPU only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6d25128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.ngpu = ngpu\n",
    "\n",
    "        # Generator network composed of a stack of transposed conv blocks\n",
    "        self.main = nn.Sequential(\n",
    "            self._block(INPUT_DIMENSION, NGF * 16, 4, 1, 0, bias = False),  # First layer: latent vector -> feature map\n",
    "            self._block(NGF * 16, NGF * 8, 4, 2, 1, bias = False),          # Upsample to 8 x 8\n",
    "            self._block(NGF * 8, NGF * 4, 4, 2, 1, bias = False),           # Upsample to 16 x 16\n",
    "            self._block(NGF * 4, NGF * 2, 4, 2, 1, bias = False),           # Upsample to 32 x 32\n",
    "            self._block(NGF * 2, NGF, 4, 2, 1, bias = False),               # Upsample to 64 x 64\n",
    "\n",
    "            nn.ConvTranspose2d(NGF, NC, 4, 2, 1, bias = False),      # Final upsample to 128x128 with RGB output\n",
    "            nn.Tanh()                                                # Output pixel values in [-1, 1]\n",
    "        )\n",
    "\n",
    "    # Helper function to define a generator block:\n",
    "\n",
    "    # ConvTranspose2d -> BatchNorm2d -> ReLU\n",
    "\n",
    "    def _block(self, i_channels, o_channels, kernel_size, stride, padding, bias):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                i_channels, \n",
    "                o_channels, \n",
    "                kernel_size, \n",
    "                stride, \n",
    "                padding, \n",
    "                bias = bias),\n",
    "            nn.BatchNorm2d(o_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7581479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.ngpu = ngpu\n",
    "\n",
    "        # Discriminator network composed of downsampling conv blocks\n",
    "        self.main = nn.Sequential(\n",
    "            self._block(NC, NDF, 4, 2, 1, bias = False, use_batchNorm2D = False), # First block: no BatchNorm\n",
    "            self._block(NDF,     NDF * 2, 4, 2, 1, bias = False),                 # Downsample to 32 x 32\n",
    "            self._block(NDF * 2, NDF * 4, 4, 2, 1, bias = False),                 # Downsample to 16 x 16\n",
    "            self._block(NDF * 4, NDF * 8, 4, 2, 1, bias = False),                 # Downsample to 8 x 8\n",
    "            self._block(NDF * 8, NDF * 16, 4, 2, 1, bias = False),                # Downsample to 4 x 4\n",
    "\n",
    "            nn.Conv2d(NDF * 16, 1, 4, 1, 0, bias = False),                        # Final layer: reduce to 1 x 1\n",
    "            nn.Sigmoid()                                                          # Output probability [0, 1] of real v.s. fake\n",
    "        )\n",
    "\n",
    "    # Helper function to define a discriminator block:\n",
    "\n",
    "    # Conv2d -> (optional) BatchNorm2d -> LeakyReLU\n",
    "\n",
    "    def _block(self, i_channels, o_channels, kernel_size, stride, padding, bias, use_batchNorm2D = True):\n",
    "        layers = [nn.Conv2d(\n",
    "            i_channels, \n",
    "            o_channels, \n",
    "            kernel_size, \n",
    "            stride, \n",
    "            padding, \n",
    "            bias = bias)]\n",
    "        \n",
    "        if use_batchNorm2D:\n",
    "            layers.append(nn.BatchNorm2d(o_channels))\n",
    "        \n",
    "        layers.append(nn.LeakyReLU(0.2, inplace = True))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeb85cf",
   "metadata": {},
   "source": [
    "## Part 3: Training a DCGAN for Each Underrepresented Class (Cordana, Healthy, Pestalotiopsis)\n",
    "\n",
    "<p align=\"justify\">insert spiel</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "20fa7065",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN_OUTPUT_DIRECTORY_TEST = \"../model2/gan_test\" # for debugging while training\n",
    "\n",
    "def prepare_output_directories():\n",
    "\n",
    "    for cls in BANANA_CLASSES:\n",
    "        if cls != \"sigatoka\":\n",
    "            full_path = Path(GAN_OUTPUT_DIRECTORY_TEST) / cls\n",
    "\n",
    "            # If the directory exists, remove and recreate it\n",
    "            if full_path.exists():\n",
    "                shutil.rmtree(full_path)\n",
    "\n",
    "            full_path.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "prepare_output_directories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff876c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dcgan_per_class(target_class = None):\n",
    "\n",
    "    if target_class:\n",
    "        dataloader = load_gan_data(batch_size = BATCH_SIZE, target_class = target_class)\n",
    "    \n",
    "    else:\n",
    "        dataloader = load_gan_data(batch_size = BATCH_SIZE)\n",
    "\n",
    "    # Initialize Generator and Discriminator\n",
    "    netG = Generator(ngpu = NGPU).to(DEVICE)\n",
    "    netD = Discriminator(ngpu = NGPU).to(DEVICE)\n",
    "\n",
    "    # Initialize weights\n",
    "    netG.apply(initialize_weights)\n",
    "    netD.apply(initialize_weights)\n",
    "\n",
    "    # Handle multi-GPU setup if applicable\n",
    "    if (DEVICE.type == \"cuda\") and (NGPU > 1):\n",
    "        netG = nn.DataParallel(netG, list(range(NGPU)))\n",
    "        netD = nn.DataParallel(netD, list(range(NGPU)))\n",
    "\n",
    "    # Loss function\n",
    "    criterion = nn.BCELoss() # Binary Cross-Entropy Loss\n",
    "\n",
    "    # Fixed noise for generating sample outputs and tracking progress during training\n",
    "    fixed_noise = torch.randn(64, INPUT_DIMENSION, 1, 1, device = DEVICE)\n",
    "\n",
    "    # Optimizers for Generator and Discriminato\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr = LEARNING_RATE, betas = (BETA1, 0.999))\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr = LEARNING_RATE, betas = (BETA1, 0.999))\n",
    "\n",
    "    # Labels for real and fake images\n",
    "    real_label = 1.0\n",
    "    fake_label = 0.0\n",
    "\n",
    "    # Actual training\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i, (real_images, _) in enumerate(dataloader): # Iterate through batches in the dataset\n",
    "            # 1. Update Discriminator: \n",
    "            #    maximize log(D(x)) + log(1 - D(G(z)))\n",
    "\n",
    "            # 1.A. Train Discriminator on real images\n",
    "            netD.zero_grad()\n",
    "\n",
    "            # Format real batch\n",
    "            real_images = real_images.to(DEVICE)\n",
    "\n",
    "            size = real_images.size(0)\n",
    "\n",
    "            label = torch.full((size,), real_label, dtype = torch.float, device = DEVICE)\n",
    "\n",
    "            # Forward pass real images through Discriminator\n",
    "            output = netD(real_images).view(-1)\n",
    "\n",
    "            # Calculate Discriminator loss for real images\n",
    "            errD_real = criterion(output, label)\n",
    "\n",
    "            # Backpropagate error for real images\n",
    "            errD_real.backward()\n",
    "\n",
    "            # Mean output for real images\n",
    "            D_x = output.mean().item()\n",
    "\n",
    "            # 1.B. Train Discriminator on batch of all fake images\n",
    "\n",
    "            # Generate batch of latent vectors\n",
    "            noise = torch.randn(size, INPUT_DIMENSION, 1, 1, device = DEVICE)\n",
    "\n",
    "            # Generate fake images with Generator\n",
    "            fake = netG(noise)\n",
    "\n",
    "            # Classify fake images with Discriminator\n",
    "            label.fill_(fake_label)\n",
    "\n",
    "            # Forward pass fake images through Discriminator\n",
    "            output = netD(fake.detach()).view(-1)\n",
    "\n",
    "            # Calculate Discriminator loss for fake images\n",
    "            errD_fake = criterion(output, label)\n",
    "\n",
    "            # Backpropagate error for fake images\n",
    "            errD_fake.backward()\n",
    "\n",
    "            # Mean output for fake images\n",
    "            D_G_z1 = output.mean().item()\n",
    "\n",
    "            # Compute total Discriminator error = real error + fake error\n",
    "            errD = errD_real + errD_fake\n",
    "\n",
    "            # Finally update Discriminator\n",
    "            optimizerD.step()\n",
    "\n",
    "            # 2. Update Generator: \n",
    "            #    maximize log(D(G(z)))\n",
    "\n",
    "            netG.zero_grad()\n",
    "            label.fill_(real_label)  # fake labels are real for Generator cost\n",
    "\n",
    "            # Pass fake images through Discriminator\n",
    "            output = netD(fake).view(-1)\n",
    "\n",
    "            # Calculate Generator loss based on Discriminator's output\n",
    "            errG = criterion(output, label)\n",
    "\n",
    "            # Backpropagate error for Generator\n",
    "            errG.backward()\n",
    "\n",
    "            # Mean output for fake images after Generator update\n",
    "            D_G_z2 = output.mean().item()\n",
    "\n",
    "            # Finally update Generator\n",
    "            optimizerG.step()\n",
    "\n",
    "        # Debugging: Print losses and monitor training progress\n",
    "\n",
    "            if i % 50 == 0:\n",
    "                print(\n",
    "                  f\"Epoch [{epoch}/{EPOCHS}] Batch {i}/{len(dataloader)} \\\n",
    "                    Loss D: {errD.item():.4f}, loss G: {errG.item():.4f} \\\n",
    "                    D(x): {D_x:.4f}, \\\n",
    "                    D(G(z))_real: {D_G_z1:.4f}, D(G(z))_fake: {D_G_z2:.4f}\"\n",
    "                )\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                fake_images = netG(fixed_noise).detach()\n",
    "\n",
    "                if target_class:\n",
    "                    path = f\"{GAN_OUTPUT_DIRECTORY_TEST}/{target_class}\"\n",
    "                \n",
    "                else:\n",
    "                    path = GAN_OUTPUT_DIRECTORY_TEST\n",
    "\n",
    "                save_image(\n",
    "                    fake_images,\n",
    "                    os.path.join(path, f\"sample_epoch_{epoch}.png\"),\n",
    "                    normalize=True\n",
    "                )\n",
    "\n",
    "    return netG, netD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fd2ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100] Batch 0/2                     Loss D: 2.1565, loss G: 19.9218                     D(x): 0.6356,                     D(G(z))_real: 0.6733, D(G(z))_fake: 0.0000\n",
      "Epoch [1/100] Batch 0/2                     Loss D: 4.8930, loss G: 12.5076                     D(x): 0.9932,                     D(G(z))_real: 0.9767, D(G(z))_fake: 0.0000\n",
      "Epoch [2/100] Batch 0/2                     Loss D: 0.4717, loss G: 12.0453                     D(x): 0.8672,                     D(G(z))_real: 0.1865, D(G(z))_fake: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Train DCGAN for \"cordana\" class\n",
    "trained_generator_cordana, _ = train_dcgan_per_class(target_class = \"cordana\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe98212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train DCGAN for \"healthy\" class\n",
    "# trained_generator_healthy, _ = train_dcgan_per_class(target_class = \"healthy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e819ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train DCGAN for \"pestalotiopsis\" class\n",
    "# trained_generator_pestalotiopsis, _ = train_dcgan_per_class(target_class = \"pestalotiopsis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f12f3d4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
