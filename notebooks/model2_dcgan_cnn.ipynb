{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88485067",
   "metadata": {},
   "source": [
    "## Importing Needed Libraries\n",
    "\n",
    "<p align=\"justify\">insert spiel</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4359eb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: Preprocessing\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Part 2: Creating DCGAN Generator and Discriminator\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# https://docs.pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "# https://pyimagesearch.com/2021/10/25/training-a-dcgan-in-pytorch/\n",
    "# https://medium.com/@manoharmanok/implementing-dcgan-in-pytorch-using-the-celeba-dataset-a-comprehensive-guide-660e6e8e29d2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56d2cb2",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing\n",
    "\n",
    "<p align=\"justify\">insert spiel</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "411d5de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "RAW_DATA_DIR = \"../training_data\"\n",
    "GAN_SIZE = (128, 128)\n",
    "CNN_SIZE = (224, 224)\n",
    "BANANA_CLASSES  = [\"cordana\", \"healthy\", \"pestalotiopsis\", \"sigatoka\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a234d1bd",
   "metadata": {},
   "source": [
    "<p align=\"justify\">insert spiel</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8812e66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_gan = transforms.Compose([\n",
    "    transforms.Resize(GAN_SIZE),  # Resize for DCGAN\n",
    "    transforms.ToTensor(),        # Convert to tensor\n",
    "    transforms.Normalize(\n",
    "        [0.5, 0.5, 0.5], \n",
    "        [0.5, 0.5, 0.5],\n",
    "    )  # Normalize to [-1, 1] for DCGAN\n",
    "])\n",
    "\n",
    "transform_cnn = transforms.Compose([\n",
    "    transforms.Resize(CNN_SIZE),  # Resize for CNN\n",
    "    transforms.ToTensor(),        # Convert to tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ee0ae5",
   "metadata": {},
   "source": [
    "<p align=\"justify\">insert spiel</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "53e02535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gan_data(batch_size = 32, workers = 2):\n",
    "    # Load dataset with GAN transformations\n",
    "    dataset_gan = datasets.ImageFolder(root=RAW_DATA_DIR, transform = transform_gan)\n",
    "    \n",
    "    # Create DataLoader for GAN data\n",
    "    dataloader_gan = DataLoader(dataset_gan, batch_size=batch_size, shuffle = True, num_workers = workers)\n",
    "\n",
    "    return dataloader_gan\n",
    "\n",
    "def load_cnn_data(batch_size = 32, workers = 2):\n",
    "    # Load dataset with CNN transformations\n",
    "    dataset_cnn = datasets.ImageFolder(root=RAW_DATA_DIR, transform = transform_cnn)\n",
    "    \n",
    "    # Create DataLoader for CNN data\n",
    "    dataloader_cnn = DataLoader(dataset_cnn, batch_size=batch_size, shuffle = True, num_workers = workers)\n",
    "\n",
    "    return dataloader_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d5c2ea",
   "metadata": {},
   "source": [
    "<p align=\"justify\">insert spiel</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "014a3b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    classname = model.__class__.__name__\n",
    "\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        nn.init.normal_(model.weight.data, 0.0, 0.02)\n",
    "\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        nn.init.normal_(model.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(model.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2af1f2",
   "metadata": {},
   "source": [
    "## Part 2: Creating DCGAN Generator and Discriminator\n",
    "\n",
    "<p align=\"justify\">insert spiel</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33db2f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "BATCH_SIZE = 128        # Number of images per training batch\n",
    "\n",
    "INPUT_DIMENSION = 100   # Dimensionality of the generator input\n",
    "\n",
    "NC = 3                  # Number of channels in the training images\n",
    "\n",
    "NGF = 64                # Base number of feature maps in the generator\n",
    "\n",
    "NDF = 64                # Base number of feature maps in the discriminator\n",
    "\n",
    "EPOCHS = 100            # Number of training epochs\n",
    "\n",
    "LEARNING_RATE = 0.0002  # Learning rate for both optimizers\n",
    "\n",
    "BETA1 = 0.5             # Beta1 value for the Adam optimizer to help stabilize DCGAN training\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
    "\n",
    "NGPU = 1  # Number of GPUs to use (0 means CPU only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6d25128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.ngpu = ngpu\n",
    "\n",
    "        # Generator network composed of a stack of transposed conv blocks\n",
    "        self.main = nn.Sequential(\n",
    "            self._block(INPUT_DIMENSION, NGF * 16, 4, 1, 0, False),  # First layer: latent vector -> feature map\n",
    "            self._block(NGF * 16, NGF * 8, 4, 2, 1, False),          # Upsample to 8 x 8\n",
    "            self._block(NGF * 8, NGF * 4, 4, 2, 1, False),           # Upsample to 16 x 16\n",
    "            self._block(NGF * 4, NGF * 2, 4, 2, 1, False),           # Upsample to 32 x 32\n",
    "            self._block(NGF * 2, NGF, 4, 2, 1, False),               # Upsample to 64 x 64\n",
    "\n",
    "            nn.ConvTranspose2d(NGF, NC, 4, 2, 1, bias = False),      # Final upsample to 128x128 with RGB output\n",
    "            nn.Tanh()                                                # Output pixel values in [-1, 1]\n",
    "        )\n",
    "\n",
    "    # Helper function to define a generator block:\n",
    "\n",
    "    # ConvTranspose2d -> BatchNorm2d -> ReLU\n",
    "\n",
    "    def _block(self, i_channels, o_channels, kernel_size, stride, padding, bias):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                i_channels, \n",
    "                o_channels, \n",
    "                kernel_size, \n",
    "                stride, \n",
    "                padding, \n",
    "                bias),\n",
    "            nn.BatchNorm2d(o_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7581479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.ngpu = ngpu\n",
    "\n",
    "        # Discriminator network composed of downsampling conv blocks\n",
    "        self.main = nn.Sequential(\n",
    "            self._block(NC, NDF, 4, 2, 1, False, use_batchNorm2D=False), # First block: no BatchNorm\n",
    "            self._block(NDF,     NDF * 2, 4, 2, 1, False),               # Downsample to 32x32\n",
    "            self._block(NDF * 2, NDF * 4, 4, 2, 1, False),               # Downsample to 16x16\n",
    "            self._block(NDF * 4, NDF * 8, 4, 2, 1, False),               # Downsample to 8x8\n",
    "            self._block(NDF * 8, NDF * 16, 4, 2, 1, False),              # Downsample to 4x4\n",
    "\n",
    "            nn.Conv2d(NDF * 16, 1, 4, 1, 0, bias = False),               # Final layer: reduce to 1x1\n",
    "            nn.Sigmoid()                                                # Output probability [0, 1] of real vs fake\n",
    "        )\n",
    "\n",
    "    # Helper function to define a discriminator block:\n",
    "\n",
    "    # Conv2d -> (optional) BatchNorm2d -> LeakyReLU\n",
    "\n",
    "    def _block(self, i_channels, o_channels, kernel_size, stride, padding, bias, use_batchNorm2D = True):\n",
    "        layers = [nn.Conv2d(\n",
    "            i_channels, \n",
    "            o_channels, \n",
    "            kernel_size, \n",
    "            stride, \n",
    "            padding, \n",
    "            bias)]\n",
    "        \n",
    "        if use_batchNorm2D:\n",
    "            layers.append(nn.BatchNorm2d(o_channels))\n",
    "        \n",
    "        layers.append(nn.LeakyReLU(0.2, inplace = True))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeb85cf",
   "metadata": {},
   "source": [
    "## Part 3: Train a DCGAN for Each Underrepresented Class (Cordana, Healthy, Pestalotiopsis)\n",
    "\n",
    "<p align=\"justify\">insert spiel</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b919ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_by_class(dataset, class_name):\n",
    "\n",
    "    class_index = dataset.class_to_idx[class_name]\n",
    "\n",
    "    return [(image, label) for image, label in dataset if label == class_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff876c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to push soon\n",
    "\n",
    "def train_dcgan_per_class(dataloader_gan, class_name, epochs = EPOCHS):\n",
    "    # Filter the dataset for the specific class\n",
    "    filtered_data = filter_data_by_class(dataloader_gan.dataset, class_name)\n",
    "    dataset_class = torch.utils.data.TensorDataset(*zip(*filtered_data))  # Custom dataset for a single class\n",
    "    dataloader_class = DataLoader(dataset_class, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    # Initialize the generator and discriminator for the class\n",
    "    gen = Generator(ngpu = NGPU).to(DEVICE)\n",
    "    dis = Discriminator(ngpu = NGPU).to(DEVICE)\n",
    "\n",
    "    # Optimizers and loss function\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer_g = optim.Adam(gen.parameters(), lr = LEARNING_RATE, betas = (BETA1, 0.999))\n",
    "    optimizer_d = optim.Adam(dis.parameters(), lr = LEARNING_RATE, betas = (BETA1, 0.999))\n",
    "\n",
    "    # Training loop for the class-specific DCGAN\n",
    "    for epoch in range(epochs):\n",
    "        for i, (real_images, _) in enumerate(dataloader_class, 0):\n",
    "            real_images = real_images.to(DEVICE)\n",
    "\n",
    "            # Labels for real and fake images\n",
    "            real_labels = torch.ones(BATCH_SIZE, 1).to(DEVICE)\n",
    "            fake_labels = torch.zeros(BATCH_SIZE, 1).to(DEVICE)\n",
    "\n",
    "            # ========================\n",
    "            # Train the Discriminator\n",
    "            # ========================\n",
    "            dis.zero_grad()\n",
    "\n",
    "            # Forward pass with real images\n",
    "            output_real = dis(real_images)\n",
    "            d_loss_real = criterion(output_real, real_labels)\n",
    "            d_loss_real.backward()\n",
    "\n",
    "            # Generate fake images from the generator\n",
    "            noise = torch.randn(BATCH_SIZE, INPUT_DIMENSION, 1, 1, device = DEVICE)\n",
    "            fake_images = gen(noise)\n",
    "\n",
    "            # Forward pass with fake images\n",
    "            output_fake = dis(fake_images.detach())\n",
    "            d_loss_fake = criterion(output_fake, fake_labels)\n",
    "            d_loss_fake.backward()\n",
    "\n",
    "            # Update discriminator\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            optimizer_d.step()\n",
    "\n",
    "            # ========================\n",
    "            # Train the Generator\n",
    "            # ========================\n",
    "            gen.zero_grad()\n",
    "\n",
    "            # Forward pass with fake images (again)\n",
    "            output_fake = dis(fake_images)\n",
    "            g_loss = criterion(output_fake, real_labels)  # We want the generator to fool the discriminator\n",
    "            g_loss.backward()\n",
    "\n",
    "            # Update generator\n",
    "            optimizer_g.step()\n",
    "\n",
    "            # Print losses every few iterations\n",
    "            if i % 50 == 0:\n",
    "                print(f\"Class: {class_name}, Epoch [{epoch}/{epochs}], Step [{i}/{len(dataloader_class)}], \"\n",
    "                      f\"D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n",
    "\n",
    "        # Save generated images and models periodically (optional)\n",
    "        if epoch % 10 == 0:\n",
    "            save_generated_images(epoch, fake_images, class_name)\n",
    "            save_models(epoch, generator, discriminator, class_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
