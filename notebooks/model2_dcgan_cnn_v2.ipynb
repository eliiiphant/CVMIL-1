{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88485067",
   "metadata": {},
   "source": [
    "## Importing Needed Libraries\n",
    "\n",
    "<p align=\"justify\">insert spiel</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4359eb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: Data Preprocessing\n",
    "\n",
    "import torch\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset, TensorDataset\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Part 2: Creating the DCGAN Generator and Discriminator Classes\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# Part 3: Training a DCGAN for Each Underrepresented Class (Cordana, Healthy, Pestalotiopsis)\n",
    "\n",
    "import shutil\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from numpy import cos, pi\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "# https://docs.pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "# https://pyimagesearch.com/2021/10/25/training-a-dcgan-in-pytorch/\n",
    "# https://medium.com/@manoharmanok/implementing-dcgan-in-pytorch-using-the-celeba-dataset-a-comprehensive-guide-660e6e8e29d2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56d2cb2",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing\n",
    "\n",
    "<p align=\"justify\">insert spiel</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "411d5de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "RAW_DATA_DIR = \"../training_data\"\n",
    "GAN_SIZE = (128, 128)\n",
    "CNN_SIZE = (224, 224)\n",
    "BANANA_CLASSES  = [\"cordana\", \"healthy\", \"pestalotiopsis\", \"sigatoka\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89358d3e",
   "metadata": {},
   "source": [
    "<p align=\"justify\">insert spiel</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12dfc301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # Ensure deterministic behavior\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a234d1bd",
   "metadata": {},
   "source": [
    "<p align=\"justify\">insert spiel</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8812e66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_gan_b = transforms.Compose([\n",
    "    transforms.Resize(GAN_SIZE), # Resize for DCGAN\n",
    "    transforms.ToTensor(),       # To tensor\n",
    "    transforms.Normalize(\n",
    "        [0.5, 0.5, 0.5], \n",
    "        [0.5, 0.5, 0.5],\n",
    "    )  # Normalize to [-1, 1] for DCGAN\n",
    "])\n",
    "\n",
    "transform_gan_p = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(GAN_SIZE, scale = (0.9, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomApply([ # maybe remove RandomApply for reproducibility?\n",
    "        transforms.ColorJitter(\n",
    "            brightness = 0.2, \n",
    "            contrast   = 0.2, \n",
    "            saturation = 0.2, \n",
    "            hue        = 0.05,\n",
    "        ),\n",
    "    ], p = 0.7),\n",
    "    transforms.RandomApply([ # maybe remove RandomApply for reproducibility?\n",
    "        transforms.RandomAffine(\n",
    "            degrees   = 10, \n",
    "            translate = (0.1, 0.1), \n",
    "            scale     = (0.9, 1.0), \n",
    "        ),\n",
    "    ], p = 0.7),\n",
    "])\n",
    "\n",
    "transform_cnn = transforms.Compose([\n",
    "    transforms.Resize(CNN_SIZE), # Resize for CNN\n",
    "    transforms.ToTensor(),       # To tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ee0ae5",
   "metadata": {},
   "source": [
    "<p align=\"justify\">insert spiel</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53e02535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gan_data(batch_size = 32, workers = 4, target_class = None, num_variants = 10, seed = SEED_NUM, directory = RAW_DATA_DIR):\n",
    "\n",
    "    generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "    # Load full dataset with base GAN transformations\n",
    "    dataset_gan = datasets.ImageFolder(root = directory, transform = transform_gan_b)\n",
    "\n",
    "    if target_class:\n",
    "        # Get class index from the class name\n",
    "        class_index = dataset_gan.class_to_idx[target_class]\n",
    "\n",
    "        # Filter indices where target matches\n",
    "        indices = [i for i, (_, label) in enumerate(dataset_gan.samples) if label == class_index]\n",
    "\n",
    "        # Wrap in a Subset\n",
    "        dataset_gan = Subset(dataset_gan, indices)\n",
    "\n",
    "        # Create a list to store augmented images\n",
    "        augmented_images = []\n",
    "\n",
    "        rng = random.Random(seed)\n",
    "\n",
    "        # Apply augmentations to each image in the loaded dataset\n",
    "        for i in range(len(dataset_gan)):\n",
    "            image, label = dataset_gan[i]\n",
    "\n",
    "            # Generate num_variants augmented versions of image\n",
    "            for _ in range(num_variants):\n",
    "                torch.manual_seed(rng.randint(0, 999999))\n",
    "        \n",
    "                augmented_image = transform_gan_p(image)\n",
    "\n",
    "                augmented_images.append((augmented_image, label))\n",
    "\n",
    "        # Create new dataset with augmented images\n",
    "        final_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.stack([image for image, _ in augmented_images]),  # Stack all augmented images\n",
    "            torch.tensor([label for _, label in augmented_images])  # Stack all labels\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        final_dataset = dataset_gan\n",
    "\n",
    "    # Create DataLoader for the GAN data\n",
    "    dataloader_gan = DataLoader(final_dataset, batch_size = batch_size, shuffle = True, num_workers = workers, generator = generator)\n",
    "\n",
    "    return dataloader_gan\n",
    "\n",
    "def load_cnn_data(batch_size = 32, workers = 4):\n",
    "    # Load dataset with CNN transformations\n",
    "    dataset_cnn = datasets.ImageFolder(root=RAW_DATA_DIR, transform = transform_cnn)\n",
    "    \n",
    "    # Create DataLoader for the CNN data\n",
    "    dataloader_cnn = DataLoader(dataset_cnn, batch_size=batch_size, shuffle = True, num_workers = workers)\n",
    "\n",
    "    return dataloader_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2af1f2",
   "metadata": {},
   "source": [
    "## Part 2: Creating the DCGAN Generator and Discriminator Classes\n",
    "\n",
    "<p align=\"justify\">insert spiel</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "33db2f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "SEED_NUM = 42            # Seed number for reproducibility\n",
    "\n",
    "BATCH_SIZE = 128         # Number of images per training batch\n",
    "\n",
    "INPUT_DIMENSION = 100    # Dimensionality of the generator input\n",
    "\n",
    "NC = 3                   # Number of channels in the training images\n",
    "\n",
    "NGF = 64                 # Base number of feature maps in the Generator\n",
    "\n",
    "NDF = 64                 # Base number of feature maps in the Discriminator\n",
    "\n",
    "EPOCHS = 200             # Number of training epochs\n",
    "\n",
    "CHECKPOINT = 10           # Checkpoint number for model saving\n",
    "\n",
    "LEARNING_RATE_G = 0.0002 # Learning rate for the Generator\n",
    "\n",
    "LEARNING_RATE_D = 0.0001 # Learning rate for the Discriminator\n",
    "\n",
    "LEARNING_RATE_D = 0.0001 # Learning rate for the CNN\n",
    "\n",
    "BETA1 = 0.5              # Beta1 value for the Adam optimizer to help stabilize DCGAN training\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
    "\n",
    "NGPU = 1  # Number of GPUs to use (0 means CPU only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e6d25128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.ngpu = ngpu\n",
    "\n",
    "        # Generator network composed of a stack of transposed conv blocks\n",
    "        self.main = nn.Sequential(\n",
    "            self._block(INPUT_DIMENSION, NGF * 16, 4, 1, 0, bias = False),  # First layer: latent vector -> feature map\n",
    "            self._block(NGF * 16, NGF * 8, 4, 2, 1, bias = False),          # Upsample to 8 x 8\n",
    "            self._block(NGF * 8, NGF * 4, 4, 2, 1, bias = False),           # Upsample to 16 x 16\n",
    "            self._block(NGF * 4, NGF * 2, 4, 2, 1, bias = False),           # Upsample to 32 x 32\n",
    "            self._block(NGF * 2, NGF, 4, 2, 1, bias = False),               # Upsample to 64 x 64\n",
    "\n",
    "            nn.ConvTranspose2d(NGF, NC, 4, 2, 1, bias = False),             # Final upsample to 128 x 128 with RGB output\n",
    "            nn.Tanh()                                                       # Output pixel values in [-1, 1]\n",
    "        )\n",
    "\n",
    "    # Helper function to define a generator block:\n",
    "\n",
    "    # ConvTranspose2d -> InstanceNorm2d -> ReLU -> Dropout\n",
    "\n",
    "    def _block(self, i_channels, o_channels, kernel_size, stride, padding, bias):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                i_channels, \n",
    "                o_channels, \n",
    "                kernel_size, \n",
    "                stride, \n",
    "                padding, \n",
    "                bias = bias),\n",
    "            nn.InstanceNorm2d(o_channels, affine = True),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.3) # Dropout to help regularize on small data\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7581479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.ngpu = ngpu\n",
    "\n",
    "        # Discriminator network composed of downsampling conv blocks\n",
    "        self.main = nn.Sequential(\n",
    "            self._block(NC, NDF, 4, 2, 1, bias = False, use_instanceNorm2d = False), # First block: no InstanceNorm2d\n",
    "            self._block(NDF, NDF *  2, 4, 2, 1, bias = False),                       # Downsample to 32 x 32\n",
    "            self._block(NDF * 2, NDF *  4, 4, 2, 1, bias = False),                   # Downsample to 16 x 16\n",
    "            self._block(NDF * 4, NDF *  8, 4, 2, 1, bias = False),                   # Downsample to 8 x 8\n",
    "            self._block(NDF * 8, NDF * 16, 4, 2, 1, bias = False),                   # Downsample to 4 x 4\n",
    "\n",
    "            nn.Conv2d(NDF * 16, 1, 4, 1, 0, bias = False),                           # Final layer: reduce to 1 x 1\n",
    "        )\n",
    "\n",
    "    # Helper function to define a discriminator block:\n",
    "\n",
    "    # Conv2d -> (optional) InstanceNorm2d -> LeakyReLU\n",
    "\n",
    "    def _block(self, i_channels, o_channels, kernel_size, stride, padding, bias, use_instanceNorm2d = True):\n",
    "        layers = [nn.Conv2d(\n",
    "            i_channels, \n",
    "            o_channels, \n",
    "            kernel_size, \n",
    "            stride, \n",
    "            padding, \n",
    "            bias = bias)]\n",
    "        \n",
    "        if use_instanceNorm2d:\n",
    "            layers.append(nn.InstanceNorm2d(o_channels, affine = True))\n",
    "        \n",
    "        layers.append(nn.LeakyReLU(0.2, inplace = True))\n",
    "        layers.append(nn.Dropout(0.3)) # Dropout to help regularize on small data\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, inp, return_features=False):\n",
    "        x = inp\n",
    "\n",
    "        for i, layer in enumerate(self.main):\n",
    "            x = layer(x)\n",
    "            if return_features and i == 4: \n",
    "                return x \n",
    "\n",
    "        return x            \n",
    "        # return self.main(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeb85cf",
   "metadata": {},
   "source": [
    "## Part 3: Training a DCGAN for All Classes\n",
    "\n",
    "<p align=\"justify\">insert spiel</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "014a3b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    classname = model.__class__.__name__\n",
    "\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        nn.init.normal_(model.weight.data, 0.0, 0.02)\n",
    "\n",
    "    elif classname.find(\"InstanceNorm\") != -1:\n",
    "        nn.init.normal_(model.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(model.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "be62701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_dataset(target_classes = BANANA_CLASSES, output_dir='../model2/balanced2', max_samples=425, seed=SEED_NUM):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # Load dataset once to share class_to_idx\n",
    "    base_dataset = datasets.ImageFolder(root=RAW_DATA_DIR, transform=transform_gan_b)\n",
    "\n",
    "    for class_name in target_classes:\n",
    "        class_idx = base_dataset.class_to_idx[class_name]\n",
    "\n",
    "        # Collect all indices of this class\n",
    "        indices = [i for i, (_, label) in enumerate(base_dataset.samples) if label == class_idx]\n",
    "        n_original = len(indices)\n",
    "\n",
    "        # Subset dataset for this class\n",
    "        class_subset = Subset(base_dataset, indices)\n",
    "\n",
    "        # Determine how many augmentations per original image\n",
    "        aug_per_image = max_samples // n_original\n",
    "        remainder = max_samples % n_original\n",
    "\n",
    "        augmented_images = []\n",
    "\n",
    "        for i, (image, _) in enumerate(tqdm(class_subset, desc=f\"Augmenting {class_name}\")):\n",
    "            for _ in range(aug_per_image):\n",
    "                augmented_images.append(transform_gan_p(image))\n",
    "\n",
    "        # Add extra samples to reach exactly max_samples\n",
    "        remainder_indices = random.choices(range(n_original), k=remainder)\n",
    "        for idx in remainder_indices:\n",
    "            image, _ = class_subset[idx]\n",
    "            augmented_images.append(transform_gan_p(image))\n",
    "\n",
    "        # Save images to disk\n",
    "        class_dir = os.path.join(output_dir, class_name)\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "        for i, image in enumerate(augmented_images):\n",
    "            save_image(image, os.path.join(class_dir, f\"{i}.png\"))\n",
    "\n",
    "    print(\"Dataset is balanced.\")\n",
    "\n",
    "# create_balanced_dataset()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad99b790",
   "metadata": {},
   "source": [
    "<p align=\"justify\">insert spiel</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "20fa7065",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN_OUTPUT_DIRECTORY_TEST = \"../model2/gan_test\" # for debugging while training\n",
    "\n",
    "def prepare_output_directory(resume = False):\n",
    "    for cls in [\"base\"] + BANANA_CLASSES:\n",
    "        if cls != \"sigatoka\":\n",
    "            full_path = Path(GAN_OUTPUT_DIRECTORY_TEST) / cls\n",
    "\n",
    "            # Only remove and recreate the directory if not resuming\n",
    "            if not resume and full_path.exists():\n",
    "                shutil.rmtree(full_path)\n",
    "\n",
    "            full_path.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "# prepare_output_directory(resume = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff876c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dcgan(resume = False, checkpoint_path = None, balanced_path = None):\n",
    "    # Set random seed for reproducibility\n",
    "    set_seed(SEED_NUM)\n",
    "\n",
    "    # Load dataset and define save path\n",
    "    if balanced_path:  \n",
    "        save_path = \"../model2/final_dcgan\"\n",
    "\n",
    "        dataloader = load_gan_data(batch_size = BATCH_SIZE, directory = balanced_path)\n",
    "\n",
    "    else:\n",
    "        save_path = GAN_OUTPUT_DIRECTORY_TEST\n",
    "        \n",
    "        dataloader = load_gan_data(batch_size = BATCH_SIZE)\n",
    "\n",
    "    # Initialize Generator and Discriminator\n",
    "    netG = Generator(ngpu = NGPU).to(DEVICE)\n",
    "    netD = Discriminator(ngpu = NGPU).to(DEVICE)\n",
    "\n",
    "    # Handle multi-GPU setup if applicable\n",
    "    if (DEVICE.type == \"cuda\") and (NGPU > 1):\n",
    "        netG = nn.DataParallel(netG, list(range(NGPU)))\n",
    "        netD = nn.DataParallel(netD, list(range(NGPU)))\n",
    "\n",
    "    # Fixed noise for generating sample outputs and tracking progress during training\n",
    "    fixed_generator = torch.Generator(device=DEVICE).manual_seed(SEED_NUM)\n",
    "\n",
    "    fixed_noise = torch.randn(64, INPUT_DIMENSION, 1, 1, device = DEVICE, generator = fixed_generator)\n",
    "\n",
    "    # Optimizers for Generator and Discriminator\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr = LEARNING_RATE_D, betas = (BETA1, 0.999))\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr = LEARNING_RATE_G, betas = (BETA1, 0.999))\n",
    "\n",
    "    # Schedulers for optimizers\n",
    "    schedulerD = torch.optim.lr_scheduler.CosineAnnealingLR(optimizerD, T_max = EPOCHS, eta_min = 1e-6)\n",
    "    schedulerG = torch.optim.lr_scheduler.CosineAnnealingLR(optimizerG, T_max = EPOCHS, eta_min = 1e-6)\n",
    "\n",
    "    # Default starting epoch\n",
    "    start_epoch = 0\n",
    "\n",
    "    # Loads checkpoint dcgan if provided \n",
    "\n",
    "    # Train base dcgan from a checkpoint\n",
    "    if checkpoint_path and os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location = DEVICE)\n",
    "        netG.load_state_dict(checkpoint[\"netG\"])\n",
    "        netD.load_state_dict(checkpoint[\"netD\"])\n",
    "\n",
    "        # Loads checkpoint optimizers if resuming training\n",
    "        if resume:\n",
    "            optimizerG.load_state_dict(checkpoint[\"optimizerG\"])\n",
    "            optimizerD.load_state_dict(checkpoint[\"optimizerD\"])\n",
    "            start_epoch = checkpoint[\"epoch\"] + 1\n",
    "\n",
    "    # Else, fresh start\n",
    "    else:\n",
    "        netG.apply(initialize_weights)\n",
    "        netD.apply(initialize_weights)\n",
    "\n",
    "    # Loss function\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Labels for real and fake images\n",
    "    real_label = 0.9 # Slightly less than 1\n",
    "    fake_label = 0.1 # Slightly more than 0\n",
    "\n",
    "    # Actual training\n",
    "    for epoch in range(start_epoch, EPOCHS):\n",
    "        # Calculate noise magnitude decay\n",
    "        noise_magnitude = 0.1 * 0.5 * (1 + cos(pi * epoch / EPOCHS)) # 0.1 = maximum noise magnitude\n",
    "    \n",
    "        for i, (real_images, _) in enumerate(dataloader): # Iterate through batches in the dataset\n",
    "            # 1. Update Discriminator: \n",
    "            #    maximize log(D(x)) + log(1 - D(G(z)))\n",
    "\n",
    "            # 1.A. Train Discriminator on real images\n",
    "            netD.zero_grad()\n",
    "\n",
    "            # Format real batch\n",
    "            real_images = real_images.to(DEVICE)\n",
    "\n",
    "            # Well, train the Discriminator on noisy real images\n",
    "            noise = torch.randn_like(real_images) * noise_magnitude # noise magnitude decays\n",
    "\n",
    "            noisy_real_images = real_images + noise\n",
    "\n",
    "            size = real_images.size(0)\n",
    "\n",
    "            label = torch.full((size,), real_label, dtype = torch.float, device = DEVICE)\n",
    "\n",
    "            # Forward pass noisy real images through Discriminator\n",
    "            output = netD(noisy_real_images).view(-1)\n",
    "\n",
    "            # Calculate Discriminator loss for noisy real images\n",
    "            errD_real = criterion(output, label)\n",
    "\n",
    "            # Backpropagate error for noisy real images\n",
    "            errD_real.backward()\n",
    "\n",
    "            # Mean output for noisy real images\n",
    "            D_x = output.mean().item()\n",
    "\n",
    "            # 1.B. Train Discriminator on batch of all fake images\n",
    "\n",
    "            # Generate batch of latent vectors\n",
    "            generator = torch.Generator(device=DEVICE).manual_seed(SEED_NUM + epoch)\n",
    "\n",
    "            noise = torch.randn(size, INPUT_DIMENSION, 1, 1, device = DEVICE, generator = generator)\n",
    "\n",
    "            # Generate fake images with Generator\n",
    "            fake = netG(noise)\n",
    "\n",
    "            # Classify fake images with Discriminator\n",
    "            label.fill_(fake_label)\n",
    "\n",
    "            # Forward pass fake images through Discriminator\n",
    "            output = netD(fake.detach()).view(-1)\n",
    "\n",
    "            # Calculate Discriminator loss for fake images\n",
    "            errD_fake = criterion(output, label)\n",
    "\n",
    "            # Backpropagate error for fake images\n",
    "            errD_fake.backward()\n",
    "\n",
    "            # Clip Discriminator gradients for stability\n",
    "            torch.nn.utils.clip_grad_norm_(netD.parameters(), max_norm = 1.0)\n",
    "\n",
    "            # Mean output for fake images\n",
    "            D_G_z1 = output.mean().item()\n",
    "\n",
    "            # Compute total Discriminator error = real error + fake error\n",
    "            errD = errD_real + errD_fake\n",
    "\n",
    "            # Finally update Discriminator\n",
    "            optimizerD.step()\n",
    "\n",
    "            # 2. Update Generator: \n",
    "            #    maximize log(D(G(z)))\n",
    "\n",
    "            netG.zero_grad()\n",
    "            label.fill_(real_label)  # fake labels are real for Generator cost\n",
    "\n",
    "            # Pass fake images through Discriminator\n",
    "            output = netD(fake).view(-1)\n",
    "\n",
    "            # Calculate Generator loss based on Discriminator's output\n",
    "            errG = criterion(output, label)\n",
    "\n",
    "            # Backpropagate error for Generator\n",
    "            errG.backward()\n",
    "\n",
    "            # Mean output for fake images after Generator update\n",
    "            D_G_z2 = output.mean().item()\n",
    "\n",
    "            # Finally update Generator\n",
    "            optimizerG.step()\n",
    "\n",
    "            # Debugging: Print losses and monitor training progress\n",
    "\n",
    "            if i in [0, len(dataloader)//2]:\n",
    "                print(\n",
    "                  f\"Epoch [{epoch}/{EPOCHS}] Batch {i}/{len(dataloader)} \\\n",
    "                    Loss D: {errD.item():.4f}, loss G: {errG.item():.4f} \\\n",
    "                    D(x): {D_x:.4f}, \\\n",
    "                    D(G(z))_real: {D_G_z1:.4f}, D(G(z))_fake: {D_G_z2:.4f}\"\n",
    "                )\n",
    "\n",
    "        # Step learning rate schedulers\n",
    "        schedulerD.step()\n",
    "        schedulerG.step()\n",
    "\n",
    "        if epoch % CHECKPOINT == 0:\n",
    "            fake_images = netG(fixed_noise).detach()\n",
    "\n",
    "            # root folder of save path, else /base if base dcgan\n",
    "            path = f\"{save_path}{\"\" if balanced_path else \"/base\"}\"\n",
    "\n",
    "            # Save images Generator could produce during checkpoints\n",
    "            save_image(\n",
    "                fake_images,\n",
    "                os.path.join(path, f\"sample_epoch_{epoch}.png\"),\n",
    "                normalize = True\n",
    "            )\n",
    "\n",
    "            # Save model version\n",
    "            save_dict = {\n",
    "                \"epoch\": epoch,\n",
    "                \"netG\": netG.state_dict(),\n",
    "                \"netD\": netD.state_dict(),\n",
    "                \"optimizerG\": optimizerG.state_dict(),\n",
    "                \"optimizerD\": optimizerD.state_dict(),\n",
    "            }\n",
    "\n",
    "            torch.save(save_dict, os.path.join(path, f\"checkpoint_epoch_{epoch}.pth\"))\n",
    "\n",
    "    torch.save({\n",
    "        \"epoch\": EPOCHS,\n",
    "        \"netG\": netG.state_dict(),\n",
    "        \"netD\": netD.state_dict(),\n",
    "        \"optimizerG\": optimizerG.state_dict(),\n",
    "        \"optimizerD\": optimizerD.state_dict(),\n",
    "    }, os.path.join(f\"{save_path}\", f\"{\"final\" if balanced_path else \"base\"}_dcgan_final.pth\"))\n",
    "\n",
    "    return netG, netD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a8d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, dcgan_discriminator = train_dcgan(resume = True, checkpoint_path= '../model2/final_dcgan/checkpoint_epoch_90.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088dc2fd",
   "metadata": {},
   "source": [
    "## Part 4: Extract features from DCGAN\n",
    "\n",
    "<p align=\"justify\">insert spiel</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ac4a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(discriminator, balanced_path = GAN_OUTPUT_DIRECTORY_BALANCED):\n",
    "    discriminator.eval()\n",
    "\n",
    "    # Set random seed for reproducibility\n",
    "    set_seed(SEED_NUM)\n",
    "\n",
    "    # Load dataset\n",
    "    dataloader = load_gan_data(batch_size = BATCH_SIZE, directory = balanced_path)\n",
    "    \n",
    "    # Accumulators\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Set to eval mode\n",
    "    discriminator.eval()  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(DEVICE)\n",
    "            features = discriminator(images, return_features=True) \n",
    "            all_features.append(features.cpu())\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    # Shape: (total_images, N), (total_images,)\n",
    "    all_features = torch.cat(all_features) \n",
    "    all_labels = torch.cat(all_labels) \n",
    "\n",
    "    return all_features, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e216d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_features, leaf_labels = feature_extractor(discriminator = dcgan_discriminator, balanced_path = GAN_OUTPUT_DIRECTORY_BALANCED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c127158",
   "metadata": {},
   "source": [
    "## Part 5: Define CNN architecture, training\n",
    "\n",
    "insert spiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c91d96dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridCNNClassifier(nn.Module):\n",
    "    def __init__(self, disc):\n",
    "        super().__init__()\n",
    "\n",
    "        # Up to intermediate layer\n",
    "        self.gan_features = nn.Sequential(*list(disc.main.children())[:4])  \n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        self.resnet.fc = nn.Identity()\n",
    "\n",
    "        # Combine feature dimensions (adjust as needed)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(gan_feat_dim + resnet_feat_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        gan_feat = self.gan_features(x)\n",
    "        gan_feat = gan_feat.view(x.size(0), -1)\n",
    "\n",
    "        resnet_feat = self.resnet(x)\n",
    "\n",
    "        combined = torch.cat((gan_feat, resnet_feat), dim=1)\n",
    "        return self.classifier(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81610cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_classifier(batch_size = 32, workers = 4, features = None, labels = None, checkpoint_path = None, discriminator = None):\n",
    "    feature_dataset = TensorDataset(features, labels)\n",
    "    feature_loader = DataLoader(feature_dataset, batch_size=batch_size, shuffle=True, num_workers = workers)\n",
    "\n",
    "    model = HybridCNNClassifier(discriminator, num_classes=len(BANANA_CLASSES)).to(DEVICE)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE_CNN)\n",
    "\n",
    "    if checkpoint_path and os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "\n",
    "        model.load_state_dict(checkpoint[\"model_state\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "\n",
    "        start_epoch = checkpoint[\"epoch\"]\n",
    "\n",
    "    # TO ADD: setting up of save folder!\n",
    "        \n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        for batch_x, batch_y in feature_loader:\n",
    "            batch_x, batch_y = batch_x.to(DEVICE), batch_y.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "        \n",
    "        if epoch % CHECKPOINT == 0:\n",
    "            checkpoint_path = os.path.join(\"../model2/cnn_classifier\", f\"cnn_classifier_epoch_{epoch}.pth\")\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "    checkpoint_path = os.path.join(\"../model2/cnn_classifier\", f\"cnn_classifier_final.pth\")\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bd8c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_classifier = cnn_classifier(features = leaf_features, labels = leaf_labels, discriminator = dcgan_discriminator)\n",
    "\n",
    "# leaf_classifier = cnn_classifier(features = leaf_features, labels = leaf_labels, checkpoint_path = \"../model2/cnn_classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec66324",
   "metadata": {},
   "source": [
    "## Part 6: Testing and evaluation\n",
    "\n",
    "insert spiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5870c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
